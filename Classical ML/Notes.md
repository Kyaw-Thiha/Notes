$y_{i} = f(x_i) + \epsilon_{i}$

$\hat{y} = \hat{f}(x)$

$\hat{y}^* = \hat{f}^*(x^*)$


Radial basis func

1. Get data
2. Select model + hypthesis space
3. $L(\hat{y_{i}}, y_{i})$ = $(\hat{y}_{i} - y_{i})^2$
   $J(w, b) = \frac{1}{2N} \sum^N_{i=1} (\hat{y}_{i} - y_{i})^2$
4. Optimize the objective function

semi-postive matrix
$\vec{x}^T.A.\vec{x} \geq 0$ where $\vec{x} \neq \vec{0}$
which guarantees that we don't end up in saddle point



Conditioning & Regularization
Condtition Number


energy function do not normalize over data point count.

gradiant descent notes

bayes variation
bayes rule
estimation

