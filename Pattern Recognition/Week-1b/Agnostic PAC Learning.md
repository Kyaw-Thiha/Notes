# Agnostic PAC Learning
#ml/statistical-learning/agnostic-pac-learning
`Agnostic PAC Learning` is [[PAC Learning]] that removes the assumption of `realizability`.

> Essentially, it admits that no perfect `hypothesis` exists.
> Either because hypothesis class is too simple, or data is too noisy.

---
## Giving up on Realizability
Recall that realizability requires
$$
\exists h^* \in \mathcal{H} \text{ s.t }
p_{x \sim \mathcal{D}}[h^*(x) = f(x)] \ = 1
$$
where
- $\mathcal{D}: \mathcal{X} \to [0, 1]$ is the data distribution
- $f: \mathcal{X} \to \mathcal{Y}$ is the true target function

`Modelling Noise`
Now, let's replace $\mathcal{D}$ and $f(x)$ with a new joint distribution $\mathcal{D}$ over $\mathcal{X} \times \mathcal{Y}$.

This means that the input samples and their labels are both generated randomly.
This allows us to model noise in the labels.

Breaking $\mathcal{D}$ down into two components, we get
1. $\mathcal{D_{\mathcal{X}}}$: The `marginal distribution` over input domain $\mathcal{X}$
2. $\mathcal{D}_{y \ | \ x}$: The `conditional distribution` over labels for points in the domain $\mathcal{Y}$

---
## Empirical Risk
We now define true error with respect to the new distribution $\mathcal{D}$.
$$
\begin{align}
L_{\mathcal{D}}  
&\triangleq p_{(x, y) \sim \mathcal{D}} [h(x) \neq y]
\\[6pt]

&\triangleq D(\{ x, y \}: h(x) \neq y)
\\[6pt]
\end{align}
$$

However, the [[Empirical Risk Minimization (ERM)#Empirical Risk|Empirical Risk]] remains the same: 
$$
L_{S}(h)
\triangleq \frac{1}{m}
|\{ i \in [m]: h(x_{i}) \neq y_{i} \}|
$$

Hence, the [[Empirical Risk Minimization (ERM)]] becomes
> Find a hypothesis $h: \mathcal{X} \to \mathcal{Y}$ that $(\text{probably approximately})$ minimizes the true risk $L_{\mathcal{D}}(h)$.

---
## Agnostic PAC Learning Definition

A `hypothesis class` $\mathcal{H}$ is `agnostic PAC learnable` if there exists 
- a function $m_{\mathcal{H}}: ] 0,1 [^2 \to \mathbb{N}$ 
- and a learning algorithm $A(S)$

with the following property

> - For every $\epsilon, \delta \in ] 0,1 [$ and for every distribution $\mathcal{D}$ over $\mathcal{X} \times \mathcal{Y}$, 
> - when running the algorithm on $m \geq m_{\mathcal{H}}(\epsilon, \delta)$ $i.i.d$ examples generated by $\mathcal{D}$
> - $A(S)$ returns a hypothesis $h$ such that
$$
L_{\mathcal{D}}(h) 
\leq \min_{h' \in \mathcal{H}} L_{\mathcal{D}}(h') 
+ \epsilon
$$
> with a probability of at least $1-\delta$ $(\text{confidence parameter})$.

---
## Generalized Loss Function
A [[Loss Function]] can be defined as
$$
\mathcal{l} 
= \mathcal{H} \times \mathcal{X}
\times \mathcal{Y}
\to \mathbb{R}_{+}
$$
where
- $\mathcal{H}$ is the `hypothesis space` with $h \in \mathcal{H}$
- $\mathcal{X}$ is the `input feature space` with $x \in \mathcal{X}$
- $\mathcal{Y}$ is the `output label space` with $y \in \mathcal{Y}$

For sake of compactness, let $\mathcal{Z} = \mathcal{X} \times \mathcal{Y}$. 
Then,
$$
\mathcal{l} 
= \mathcal{H} \times \mathcal{Z}
\to \mathbb{R}_{+}
$$
Using this, we can re-define the [[Risk Function|True Risk Function]] as
$$
L_{\mathcal{D}}(h)
\triangleq \mathbb{E}_{z \sim \mathcal{D}} 
[\mathcal{l}(h, z)]
$$
Likewise, the [[Empirical Risk]] can be re-defined as
$$
L_{S}(h)
\triangleq \frac{1}{m}
\sum^m_{i=1} \mathcal{l}(h, z_{i})
$$
---
## Agnostic PAC Learning for General Loss Function
A `hypothesis class` $\mathcal{H}$ is `agnostic PAC learnable` with respect to a `set` $\mathcal{Z}$ **and a `loss function`** $l: \mathcal{H} \times \mathcal{Z} \to \mathbb{R}_{+}$ if there exists 
- a function $m_{\mathcal{H}}: ] 0,1 [^2 \to \mathbb{N}$ 
- and a learning algorithm $A(S)$

with the following property

> - For every $\epsilon, \delta \in ] 0,1 [$ and for every distribution $\mathcal{D}$ over $\mathcal{X} \times \mathcal{Y}$, 
> - when running the algorithm on $m \geq m_{\mathcal{H}}(\epsilon, \delta)$ $i.i.d$ examples generated by $\mathcal{D}$
> - $A(S)$ returns a hypothesis $h$ such that
$$
L_{\mathcal{D}}(h) 
\leq L_{h' \in \mathcal{H}_{\mathcal{D}}}(h') 
+ \epsilon
$$
> with a probability of at least $1-\delta$ $(\text{confidence parameter})$.

**where $L_{D}(h) = \mathbb{E}_{z \sim \mathcal{D}}[l(h, z)]$.**

---
## Learning via Uniform Convergence
We have previously shown that assuming `realizability`, any `finite hypothesis class` $h \in \mathcal{H}$ is `PAC Learnable`.

> `Uniform Convergence` implies that any finite hypothesis class $h \in \mathcal{H}$ is `Agnostic PAC Learnable` (via `ERM`), provided its `loss function` is bounded.
> Proof is in Understanding Machine Learning, Chapter-4

`Uniform Convergence Bound`
For a `finite hypothesis class`, uniform convergence gives
$$
m_{\mathcal{H}}^{UC}
\leq \frac{\log \mathcal{|H|} + \log(2/\delta)}{\epsilon^2}
$$

---
## Infinite Hypothesis Classes

> `Hypothesis classes` are parameterized by real number.
But computers approximate real numbers with finite binary representations of rational number.
This is called `discretization trick`.



`Example`
Suppose we have a `hypothesis class` $h \in \mathcal{H}$ 
- with $d$ free parameters, and
- using $64\text{-bit}$ numbers

Then, we can replace $|\mathcal{H}|$ with $2^{64d}$ to get
$$
\log |\mathcal{H}|
= \log(2^{64d})
= 64d \log(2)
\approx 64d \cdot0.693
$$
Substituting it in,
$$
m_{\mathcal{H}}^{UC}
\leq \left[  
\frac{128d + 2 \log(2/\delta)}{\epsilon^2}  
\right]
$$

---
## See Also
- [[Empirical Risk]]
- [[Empirical Risk Minimization (ERM)]]
- [[PAC Learning]]
- [[Risk Function]]
- [[Loss Function]]
