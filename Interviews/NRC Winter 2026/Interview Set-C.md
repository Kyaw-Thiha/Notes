# Interview Practice Set C — Practical / Engineering-Focused

## 1. Background
- What experience do you have with building real systems?
- What was the largest ML project you've worked on?

## 2. Python / Software Engineering
- How would you organize a repo for an evaluation pipeline?
- How do you handle configuration management for experiments?
- What tools do you use for profiling Python code?

## 3. Object Detection & Tracking
- Explain IoU in 30 seconds.
- Explain mAP in 30 seconds.
- When is IoU misleading or insufficient?
- What makes multi-object tracking harder than single-object?

## 4. Evaluation & Benchmarking
- What metrics would you choose for real-time tracking on a mobile robot?
- How would you compare two models with different output formats?
- How do you ensure consistent preprocessing across datasets?

## 5. Scenario-Based Questions
- You have a folder of 10k frames and 10k labels but some are misaligned — what do you do?
- Your detection model has high recall but poor precision — how do you fix it?
- You benchmark two models but one randomly crashes every 300 frames — what steps do you take?

## 6. Collaboration & Documentation
- How would you document your evaluation scripts for someone joining next year?
- How do you ensure your code integrates smoothly with a team’s codebase?
- How would you verify that your pipeline matches published metrics?

## 7. Reflection
- What excites you about evaluating models?
- How do you stay updated with tracking research?
