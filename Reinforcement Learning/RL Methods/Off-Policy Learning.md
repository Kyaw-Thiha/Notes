# Off-Policy Learning
#rl/off-policy

`Off-Policy Learning` refers to learning about one policy (`target policy`) while following another `(behavior policy)` to collect experience.

This allows the agent to learn optimal behavior from data generated by a different policy.

In off-policy methods:
- `Behavior policy`: used for inference.  
- `Target policy`: used for training.

## Example
In **Q-Learning**, the agent acts with an Îµ-greedy policy (exploratory), but updates using the greedy target policy:
$$
Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \alpha [R_{t+1} + \gamma \max_a Q(S_{t+1}, a) - Q(S_t, A_t)]
$$

---

# See Also
- [[On-Policy Learning]]
- [[Q-Learning]]
- [[SARSA]]
